{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc71633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57033f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('us_accidents').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b682d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv(\"hdfs://localhost:9000/capstone_project2/us_data4.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0275219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f88136ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView(\"mytable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "235c5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = spark.sql(\"select *from mytable limit 5\")\n",
    "#result.createOrReplaceTempView(\"result_df\")\n",
    "#result.write.csv('hdfs://localhost:9000/output/result.csv', mode='overwrite', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e34c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_five_city = spark.sql(\"select city, count(*) as total_accidents from mytable group by city order by total_accidents desc limit 5\")\n",
    "top_five_city.write.csv('hdfs://localhost:9000/output/top_five_city.csv', mode='overwrite', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ab7525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+\n",
      "|       city|total_accidents|\n",
      "+-----------+---------------+\n",
      "|      Miami|           2352|\n",
      "|    Houston|           2304|\n",
      "|Los Angeles|           1999|\n",
      "|  Charlotte|           1801|\n",
      "|     Dallas|           1759|\n",
      "+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_five_city.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2e8cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_three_state = spark.sql(\"select state, count(*) as total_state_accidents from mytable group by state order by total_state_accidents desc limit 3\")\n",
    "top_three_state.write.csv('hdfs://localhost:9000/output/top_three_state', mode='overwrite', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93ffb5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------+\n",
      "|state|total_state_accidents|\n",
      "+-----+---------------------+\n",
      "|   CA|                22347|\n",
      "|   FL|                11051|\n",
      "|   TX|                 7668|\n",
      "+-----+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_three_state.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec13c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_wise_accidents = spark.sql(\"select YEAR(start_time) as accidents_year,count(*) as total_accidents from mytable group by YEAR(start_time) order by accidents_year \")\n",
    "year_wise_accidents.write.csv('hdfs://localhost:9000/output/year_wise_accidents', mode='overwrite', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34632199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+\n",
      "|accidents_year|total_accidents|\n",
      "+--------------+---------------+\n",
      "|          2016|           5370|\n",
      "|          2017|           9297|\n",
      "|          2018|          11493|\n",
      "|          2019|          12257|\n",
      "|          2020|          15267|\n",
      "|          2021|          20418|\n",
      "|          2022|          22815|\n",
      "|          2023|           3083|\n",
      "+--------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "year_wise_accidents.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a0d41e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_impact=spark.sql(\"select weather_condition, count(*) as total_weather_accidents from mytable group by weather_condition order by total_weather_accidents desc limit 10\")\n",
    "weather_impact.write.csv('hdfs://localhost:9000/output/weather_impact', mode='overwrite', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46b9120f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[weather_condition: string, total_weather_accidents: bigint]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bf70b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotspot_place_accidents=spark.sql(\"select county,state,city, count(*) as total_country_accidents from mytable group by county,state,city order by total_country_accidents desc limit 20\")\n",
    "hotspot_place_accidents.write.csv('hdfs://localhost:9000/output/hotspot_place_accidents', mode='overwrite', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b06191a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[county: string, state: string, city: string, total_country_accidents: bigint]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotspot_place_accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b0fdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
